import streamlit as st

# Sidebar
st.sidebar.title("Table of Contents")
st.sidebar.markdown("""
- [Introduction](#introduction)
    - [What is open-ended text generation?](#what-is-open-ended-text-generation)
    - [Why is evaluation of open-ended text generation important?](#why-is-evaluation-of-open-ended-text-generation-important)
    - [How is open-ended text generation currently evaluated?](#how-is-open-ended-text-generation-currently-evaluated)
- [The Problem](#the-problem)
- [MAUVE](#mauve)
    - [How to quantify quality and diversity?](#how-to-quantify-quality-and-diversity)

""")


st.caption(""" <p style='text-align: center;'> CS7150: Deep Learning | Northeastern University </p>""" , unsafe_allow_html=True)
st.caption(""" <p style='text-align: center;'> Shreyas Prasad, 2022-12-09</p>""" , unsafe_allow_html=True)




# ------------------------- Title ------------------------- #

# Center the title and subtitles
st.markdown( """ <h1 style='text-align: center;'> Evaluation metrics for open-ended text generation: A review</h1> """, unsafe_allow_html=True)
st.markdown( """ <h4 style='text-align: center;'> <i> with a special focus on the state-of-the-art metric: MAUVE </i></h4> """, unsafe_allow_html=True)









# ---------------------------------------------------------  Introduction --------------------------------------------------------- #
st.header("Introduction")


# ------------------------- What is text generation? ------------------------- #

st.subheader("What is open-ended text generation?")
st.write("""
Open-ended text generation is a type of text generation that is designed to produce realistic and coherent text without any predefined constraints or rules. This is in contrast to other types of text generation, such as machine translation or summarization, where the generated text is required to conform to certain rules or constraints.
To generate text, a language model can produce the next word given a context by using the conditional probability of the next word on the previous words:
""")

st.latex(r'P(w_{t+1}|w_{t},...,w_{1})')

st.write("""
Open-ended text generation is a challenging task because it requires the model to generate text that is not only grammatically correct and coherent, but also interesting and engaging. This requires the model to have a deep understanding of the language and the ability to generate a wide range of possible outputs.
This is done by decoding the language model with various algorithms like **beam search**, **greedy search**, **top-k sampling** and **top-p (Nucleas) sampling**. 
""")

# ------------------------- Why is it important? ------------------------- #
st.subheader("Why is evaluation of open-ended text generation important?")
st.write("""
Evaluating the performance of text generation models is a crucial step in their development because it helps to determine how well the models are able to generate realistic and coherent text. Here are a few reasons:
- The quality of the generated text is one of the key factors that determines the usefulness of a text generation model. 
- Evaluating the generated text is important for comparing different text generation models.
- Rvaluating the generated text is also important for understanding the limitations of text generation models.
""")





# ------------------------- How to evaluate open-ended text generation? ------------------------- #
# Add a subheader
st.subheader("How is open-ended text generation currently evaluated?")

# Add a text
st.write(""" ***(an analysis of popular evaluation metrics)*** """)


st.markdown("""
#### Statistical

#####  Perplexity
    
Perplexity is a common metric for evaluating language models. It is defined as the inverse probability of the test data. Mathematically, it is the exponentiation of cross entropy.

**Pros**: 
- Easy to compute, widely used in NLP
**Cons**: 
- Generally, the lower the perplexity, the better the model. But, in the domain of open-ended text generation, the lower the perplexity, the more likely the model is to repeat itself. So, the model has to achieve similiar perplexity on both human and machine generated text so that a balance between generating new text and repeating itself. But the problem with using the perplexity metric is that it is not a good measure of the quality of the text generated by the model.
- Also, it assumes perfect history, which might not always be the case when using previously generated data to generate a new word.
- ***For example***, the model can generate a text with perplexity as same as the human generated text but the model generated text can be completely nonsensical.
    """)

# st.latex(r'Perplexity = e^{CE} = e^{-\frac{1}{N}\sum_{i=1}^N logP(x_i)}')

st.markdown("""
#####  Zipf's Law

The Zipf coefficient is calculated by comparing the observed frequency of words in a text to the expected frequency of those words based on the Zipf's law, which states that the frequency of a word in a text is inversely proportional to its rank in the frequency list. 
The Zipf coefficient is calculated as the ratio of the observed frequency to the expected frequency.

**Pros**:
- Unlike metrics like Self-BLEU, which only provide a relative measure of the diversity of the generated data, Zipf coefficient can provide a direct and interpretable measure of the regularity of the generated text. This can make it easier to compare the performance of different models, and it can provide more concrete guidance on how to improve the performance of a given model.
- it takes into account the frequencies of all words in the generated text, not just individual sentences. This can provide a more comprehensive evaluation of the quality of the generated text, and it can help to identify issues with the coherence or fluency of the text as a whole.

**Cons**:
- One potential issue with using the Zipf coefficient is that it is based on the assumption that the Zipf's law accurately describes the distribution of words in a text. However, this assumption may not always hold in practice, and the Zipf's law may not be a perfect model of the distribution of words in a text. In such cases, the Zipf coefficient may not accurately reflect the quality of the language model, and it may not provide a reliable measure of the model's performance.
- It does not provide an absolute measure of the quality of the language model as it only considers the frequency of the n-grams and exluding order of the n-grams, the coherence or grammatical correctness of the generated text. 
- Also, some decoding algorithms work by truncating the tail of the word distribution, which can lead to a lower n-gram frequency but a higher quality text.


#####  Generation Perplexity

Generation perplexity is a measure of the quality of a language model that is calculated by taking the exponential of the average cross-entropy of the model's predictions on a generated dataset, unlike the perplexity metric, which is calculated on a test dataset.

**Pros**:
- It is a more accurate measure of the quality of the language model than the perplexity metric, as it is calculated on a generated dataset rather than a test dataset.

**Cons**:
- Generation perplexity only provides a partial evaluation of the quality of the generated text. By calculating the average cross-entropy of the model's predictions on a generated dataset, generation perplexity only provides information about the accuracy of the model's predictions, and it does not take into account other aspects of the generated text such as its content or its relevance to a given prompt.
- Generation perplexity can be sensitive to the choice of generated dataset. The value of the generation perplexity metric can depend heavily on the specific dataset used to calculate it, and it can be affected by factors such as the length of the generated text, the diversity of the generated text, and the difficulty of the prompts used to generate the text. Even decoding algorithms that produce similar results can produce different values of the generation perplexity metric, depending on the specific dataset used to calculate it.

""")


st.markdown("""
#### Reference-based
##### Self-BLEU

BLEU(BiLingual Evaluation Understudy) that measures the similarity between the generated text and the reference text. BLEU(N) is the number of n-grams in the candidate summary that are also in the reference summary. Self-BLEU is a metric based on BLEU which calculates the  number of n-grams in the generated text that are also in the reference text [7].

**Pros**:
- One potential benefit of using Self-BLEU is that it is a simple and intuitive measure that is easy to calculate and interpret. It is based on the BLEU metric, which is a widely-used and well-established measure of sentence similarity, and it extends this metric in a straightforward way to evaluate the diversity of generated data. As a result, Self-BLEU can be an accessible and user-friendly metric for evaluating the performance of open-ended text generation models.
- Another potential advantage of Self-BLEU is that it provides a relative measure of the diversity of generated data. By comparing the similarity of individual sentences to the rest of the generated data, Self-BLEU can provide a sense of how well the generated text is able to capture the diversity of possible outputs that the language model is capable of generating. This can be useful for identifying instances of mode collapse, where the language model is only able to generate a limited range of outputs, and for evaluating the effectiveness of different techniques for improving the diversity of generated text.


**Cons**:
- One potential issue with using Self-BLEU is that it is based on the BLEU metric, which is designed to evaluate the similarity of two sentences or texts. While this metric can be useful for assessing the quality of machine translation systems, it may not be well-suited for evaluating open-ended text generation, where the goal is to generate diverse and creative text, rather than text that is similar to a given reference text.
- The higher the self-BLEU(N), the more similar the generated text is to the reference text. Note that it is possible to have a model with a high Self-BLEU(N) that is not a good model.
- For example, self-BLEU(N) = 1, it means that all n-grams in the generated text are also in the reference text, which implies reference = model and which also implies that there is no diversity in the generated text.
- Self-BLEU also suffers from its quadratic runtime complexity as for each sample text, we need to calculate a BLEU score between that sample and the whole reference text.

""")

# --------------------------------------------------------- The Problem ---------------------------------------------------------------------------------- 


st.header("The Problem")

st.markdown("""
Open-ended text generation involves the generation of novel and unpredictable text, it can be difficult to evaluate the performance of a given model using traditional metrics such as perplexity or BLEU score.
The fundamental problem in the evaluation of open-ended text generation is the lack of a clear, objective metric for evaluating both **quality** and **diversity** of the generated text.""")

# 

st.header("MAUVE")
st.markdown("""***Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers***""")

st.subheader("How to quantify quality and diversity?")
st.markdown(""" The authors of MAUVE quantify both diversity and quality of the generated text with the notion of Type I and Type II errors respectively.

Let $P$ be the probability distribution of the human text and $Q$ be the probability distribution of the generated text. 

|     | $P(x) << 1$ | $P(x) >> 0$ |
| --- | ------- | ------- |
| $Q(x) << 1$ | - | **Type II error (TN)** |
| $Q(x)>> 0$ | **Type I error (FP)** | - |



- **Type I error (FP)**: The model assigns a high probability to a sequence that has a low probability in the human generated text which is unlike written by humans. This is a false positive error.
- **Type II error (TN)**: The model assigns a low probability to a sequence that has a high probability in the human generated text. An indication that the model is not able to generate text like human text. This is a false negative error.

#### KL Divergence

$$KL(P || Q) = \sum_{x \in \mathcal{X}} P(x) \log \\frac{P(x)}{Q(x)}$$

Using KL divergence, the authors of MAUVE formalize the notion of Type I and Type II errors. 

$KL(Q||P)$ penalizes the model for assigning a high probability to a sequence that has a low probability in the human generated text. Conversely, $KL(P||Q)$ penalizes the model for assigning a low probability to a sequence that has a high probability in the human generated text.

**Problems with KL Divergences**

- *"KL divergence is infinite if the support of the distributions are not identical"*


Consider the following two distributions $P$ and $Q$:

$$P = [0.22, 0.57, 0.12, 0.69]$$

$$Q = [0.31, 0.42, 0.12]$$

In this example, the support of distribution $P$ is the set of four elements $\{1, 2, 3, 4\}$, while the support of distribution $Q$ is the set of three elements $\{1, 2, 3\}$. 

The support of a probability distribution is the set of all possible values that a random variable can take on. In other words, it is the range of values that the random variable can assume, and it is typically defined by the domain of the distribution's underlying probability density or mass function.

Since the two distributions do not have the same support, the KL divergence between them is infinite. This is because the value of $Q$ at the fourth element (which is not in the support of $Q$) is $0$, so the log of the ratio of $P$ and $Q$ at this point is infinite. Therefore, the KL divergence between $P$ and $Q$ is also infinite.

**Solution**

*"Use a mixture distribution to ***softly*** measure the two errors"*
  
Authors define the mixture distribution is defined as follows:

$$R_{\lambda} = \lambda P + (1 - \lambda) Q$$


where $\lambda$ is a parameter that controls the relative weight of the two distributions and ranges from $0$ to $1$ **not inclusive.**

The not inclusive part is important because if $\lambda$ is $0$ or $1$, then the mixture distribution is just $P$ or $Q$ respectively. So by always keeping $\lambda$ in the range $(0, 1)$, we ensure that the mixture distribution does not have a zero probability at any point because we are always adding a non-zero probability to the mixture distribution (either $P$ or $Q$).

So the previous example would be:

$P = [0.22, 0.57, 0.12, 0.69]$

$Q = [0.31, 0.42, 0.12]$


$\lambda = 0.001$

$R_{\lambda} = 0.001 \\times [0.22, 0.57, 0.12, 0.69] + (1 - 0.001) \\times [0.31, 0.42, 0.12]$

$R_{\lambda = 0.001} = [0.3099, 0.4202, 0.12  , 0.0007]$

We see that the mixture distribution $R_{\lambda}$ has a non-zero probability at the fourth element, so the KL divergence between $P$ and $Q$ is no longer infinite.

---

> Just to point out that in the bigger scheme of things, the primary focus is to minimize both the Type I and Type II errors.

---

By exponetiating the two KL divergences and varying $\lambda$, we can get a curve that shows the trade-off between the two errors. 

"This yields a divergence curve." *(More on this later)*


$$C(P, Q) = \Big\{ \\big(\exp(-c\, KL(Q|R_\lambda)), \exp(-c\, KL(P|R_\lambda)) \\big) \Big\}_{\lambda \in [0, 1]}$$ 

where $c$ is a hyperparameter for scaling.


> Insert Figure 1 here


The metric is defined as  

$$\\text{MAUVE}(P,Q)$$

as the area under the curve $C(P, Q)$,  providing the summary of the trade-off between Type I and Type II errors. 


##### Problems with $P$


So, if given two distributions $P$ and $Q$, we can compute the area under the curve $C(P, Q)$ to get the metric $\\text{MAUVE}(P,Q)$. But the **problem** is that we do not have access to the true distribution $P$ and also the support of $P$ is large since it is the set of all possible tokens.

Authors solve these two problems by using the following two techniques:
1. Use samples $x_i$ from the true distribution $P$ and sample $\\tilde{x}_i$ from the model distribution $Q$ to approximate the true distribution $P$ and the model distribution $Q$ respectively.
2. Use a "quantized embedding space that is sensitive to important features of text"

The quantized embedding space is embeddings space of a large language model (e.g. GPT-2). With this quantized embedding space, the support of the distributions is restricted to a finite set of vectors.

This is obtained by passing the samples $x_i$ and $\\tilde{x}_i$ through a large language model (e.g. GPT-2) and using the output of the last layer as the embedding vector for the sample.
After obtaining a set of embedding vectors for the samples, the authors use a clustering algorithm to group the embedding vectors into a finite set of $k$. The clusters are then used as the support of the true distribution $P$ and the model distribution $Q$.
After the clustering, the number of samples from the true distribution $P$ and the model distribution $Q$ are counted in each cluster. By only counting the samples in each cluster, the support of the distributions is restricted to a finite set of $k$ eliminating the problem of infinite KL divergence.

So now you have $\\tilde{P}$ and $\\tilde{Q}$, which are  "a piecewise constant" approximations of the true distribution $P$ and the model distribution $Q$ respectively. These approximations are then used to compute the area under the curve $C(\\tilde{P}, \\tilde{Q})$ to get the metric $\\text{MAUVE}(\\tilde{P}, \\tilde{Q})$.

#### Advantages over other metrics

The authors have demonstrated that the metric $\\text{MAUVE}(\\tilde{P}, \\tilde{Q})$ is better than other metrics in the following ways:

1. Identification of quality differences between decoding algorithms. 
1. Quantification of quality differences due to model size.
2. Caputures the quality differences due to generation length.


#### Limitations
1. Arbitrary number of clusters $k$ is used to approximate the true distribution $P$ and the model distribution $Q$. This is a hyperparameter that needs to be tuned.
2. There are a lot of approximations in the process of obtaining $\\tilde{P}$ and $\\tilde{Q}$ from $P$ and $Q$ respectively. While these transformations doesn't guarantee unbiasedness in the KL estimations it allows tractability of calculations.
3. As this is not an absolute metric, this metric can be used as an objective function to optimize the model achieving a higher score on the metric, not guaranteeing a negative impact on the model's performance on other metrics.


""")



